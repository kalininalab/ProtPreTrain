seed_everything: true
trainer:
  logger:
    class_path: WandbLogger
    init_args:
      log_model: all
      project: step
      dir: wandb
      tags: [gcn, test]
  callbacks:
    - class_path: ModelCheckpoint
      init_args:
        monitor: val/loss
        mode: min
        dirpath: logs
    - class_path: RichProgressBar
    - class_path: RichModelSummary
    - class_path: LearningRateMonitor
    - class_path: EarlyStopping
      init_args:
        monitor: val/loss
        patience: 20
        mode: min
  gradient_clip_val: 0.0
  accelerator: gpu
  devices: -1
  max_epochs: 100
  num_sanity_val_steps: 20
  fast_dev_run: false
model:
  class_path: RegressionModel
  init_args:
    local_module: GAT
    global_module: Performer
    hidden_dim: 512
    num_layers: 4
    num_heads: 4
    dropout: 0.1
    attn_dropout: 0.1
optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 1.0e-3
lr_scheduler:
  class_path: ReduceLROnPlateau
  init_args:
    mode: min
    monitor: val/loss
    factor: 0.1
    patience: 10
    min_lr: 1.0e-7
    verbose: true
data:
  # class_path: StabilityDataModule
  init_args:
    pre_transforms:
      - class_path: torch_geometric.transforms.Center
      - class_path: torch_geometric.transforms.NormalizeRotation
    transforms:
      - class_path: torch_geometric.transforms.RadiusGraph
        init_args:
          r: 7.0
      - class_path: torch_geometric.transforms.ToUndirected
      - class_path: torch_geometric.transforms.Spherical
    num_workers: 16
    shuffle: true
    batch_sampling: false
    batch_size: 256
    # max_num_nodes: 1024
